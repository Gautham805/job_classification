{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# job_monitoring_system.py\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Constants\n",
        "BASE_URL = \"https://www.karkidi.com\"\n",
        "SEARCH_URL = \"https://www.karkidi.com/Find-Jobs/{page}/all/India?search={query}\"\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "MODEL_DIR = \"model\"\n",
        "DATA_PATH = \"data/jobs.csv\"\n",
        "N_CLUSTERS = 5\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "def log(msg):\n",
        "    print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}\")\n",
        "\n",
        "# Scrape job listings from multiple pages\n",
        "def scrape_jobs(keyword=\"data science\", pages=2):\n",
        "    jobs = []\n",
        "    query = keyword.replace(\" \", \"%20\")\n",
        "\n",
        "    for page in range(1, pages + 1):\n",
        "        url = SEARCH_URL.format(page=page, query=query)\n",
        "        log(f\"Scraping page {page}: {url}\")\n",
        "        try:\n",
        "            response = requests.get(url, headers=HEADERS, timeout=10)\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "            job_blocks = soup.find_all(\"div\", class_=\"ads-details\")\n",
        "\n",
        "            for job in job_blocks:\n",
        "                try:\n",
        "                    title = job.find(\"h4\").get_text(strip=True)\n",
        "                    company = job.find(\"a\", href=lambda x: x and \"Employer-Profile\" in x)\n",
        "                    company_name = company.get_text(strip=True) if company else \"\"\n",
        "                    location = job.find(\"p\").get_text(strip=True) if job.find(\"p\") else \"\"\n",
        "                    experience = job.find(\"p\", class_=\"emp-exp\").get_text(strip=True) if job.find(\"p\", class_=\"emp-exp\") else \"\"\n",
        "                    skills_tag = job.find(\"span\", string=\"Key Skills\")\n",
        "                    skills = skills_tag.find_next(\"p\").get_text(strip=True) if skills_tag else \"\"\n",
        "                    summary_tag = job.find(\"span\", string=\"Summary\")\n",
        "                    summary = summary_tag.find_next(\"p\").get_text(strip=True) if summary_tag else \"\"\n",
        "                    url = BASE_URL + job.find_parent(\"a\")[\"href\"] if job.find_parent(\"a\") else \"\"\n",
        "\n",
        "                    jobs.append({\n",
        "                        \"title\": title,\n",
        "                        \"company\": company_name,\n",
        "                        \"location\": location,\n",
        "                        \"experience\": experience,\n",
        "                        \"skills\": skills,\n",
        "                        \"summary\": summary,\n",
        "                        \"url\": url,\n",
        "                        \"scraped_at\": datetime.now().isoformat()\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    log(f\"‚ùå Error parsing job block: {e}\")\n",
        "                    continue\n",
        "\n",
        "            time.sleep(1)\n",
        "        except Exception as e:\n",
        "            log(f\"‚ùå Failed to fetch page {page}: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(jobs)\n",
        "    if 'skills' not in df.columns:\n",
        "        df['skills'] = \"none\"\n",
        "    return df\n",
        "\n",
        "# Preprocess skill strings\n",
        "def preprocess_skills(skills_series):\n",
        "    return skills_series.str.lower().str.replace(r\"[^a-zA-Z0-9, ]\", \"\", regex=True).fillna(\"\")\n",
        "\n",
        "# Train clustering model\n",
        "def train_model(jobs_df):\n",
        "    skills_cleaned = preprocess_skills(jobs_df['skills'])\n",
        "    vectorizer = TfidfVectorizer(tokenizer=str.split, stop_words=\"english\")\n",
        "    skill_vectors = vectorizer.fit_transform(skills_cleaned)\n",
        "\n",
        "    model = KMeans(n_clusters=N_CLUSTERS, random_state=42)\n",
        "    model.fit(skill_vectors)\n",
        "\n",
        "    jobs_df['cluster'] = model.labels_\n",
        "\n",
        "    # Evaluate with silhouette score\n",
        "    score = silhouette_score(skill_vectors, model.labels_)\n",
        "    log(f\"üìä Silhouette Score: {score:.3f}\")\n",
        "\n",
        "    # Manual inspection of clusters\n",
        "    for i in range(N_CLUSTERS):\n",
        "        log(f\"\\nüìÇ Cluster {i} sample skills:\")\n",
        "        print(jobs_df[jobs_df['cluster'] == i]['skills'].head(3).to_string(index=False))\n",
        "\n",
        "    joblib.dump(vectorizer, os.path.join(MODEL_DIR, \"skill_vectorizer.pkl\"))\n",
        "    joblib.dump(model, os.path.join(MODEL_DIR, \"clustering_model.pkl\"))\n",
        "\n",
        "    return jobs_df\n",
        "\n",
        "# Classify new jobs with saved model\n",
        "def classify_jobs(jobs_df):\n",
        "    vectorizer = joblib.load(os.path.join(MODEL_DIR, \"skill_vectorizer.pkl\"))\n",
        "    model = joblib.load(os.path.join(MODEL_DIR, \"clustering_model.pkl\"))\n",
        "\n",
        "    skills_cleaned = preprocess_skills(jobs_df['skills'])\n",
        "    skill_vectors = vectorizer.transform(skills_cleaned)\n",
        "    jobs_df['cluster'] = model.predict(skill_vectors)\n",
        "    return jobs_df\n",
        "\n",
        "# Save to CSV\n",
        "def save_jobs(jobs_df):\n",
        "    jobs_df.to_csv(DATA_PATH, index=False)\n",
        "    log(f\"‚úÖ Saved {len(jobs_df)} jobs to {DATA_PATH}\")\n",
        "\n",
        "# Notify users\n",
        "def notify_users(jobs_df, user_interest_clusters):\n",
        "    matching_jobs = jobs_df[jobs_df['cluster'].isin(user_interest_clusters)]\n",
        "    if not matching_jobs.empty:\n",
        "        log(\"üîî New jobs matching user interests:\")\n",
        "        print(matching_jobs[['title', 'company', 'location', 'url']])\n",
        "    else:\n",
        "        log(\"No matching jobs found today.\")\n",
        "\n",
        "# Main daily job\n",
        "if __name__ == \"__main__\":\n",
        "    log(\"üöÄ Starting job scraping and classification...\")\n",
        "    jobs_df = scrape_jobs(keyword=\"data science\", pages=2)\n",
        "\n",
        "    if not os.path.exists(os.path.join(MODEL_DIR, \"clustering_model.pkl\")):\n",
        "        log(\"üîß Training new clustering model...\")\n",
        "        jobs_df = train_model(jobs_df)\n",
        "    else:\n",
        "        log(\"üîé Classifying with existing model...\")\n",
        "        jobs_df = classify_jobs(jobs_df)\n",
        "\n",
        "    save_jobs(jobs_df)\n",
        "\n",
        "    # Example user preferences\n",
        "    user_interest_clusters = [0, 2]\n",
        "    notify_users(jobs_df, user_interest_clusters)\n",
        "\n",
        "    log(\"‚úÖ Job monitoring completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvOl9W9UVsUa",
        "outputId": "e2639d5d-1904-43cb-a3fd-7fc92be64ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-05-20 06:29:05] üöÄ Starting job scraping and classification...\n",
            "[2025-05-20 06:29:05] Scraping page 1: https://www.karkidi.com/Find-Jobs/1/all/India?search=data%20science\n",
            "[2025-05-20 06:29:17] Scraping page 2: https://www.karkidi.com/Find-Jobs/2/all/India?search=data%20science\n",
            "[2025-05-20 06:29:25] üîé Classifying with existing model...\n",
            "[2025-05-20 06:29:25] ‚úÖ Saved 20 jobs to data/jobs.csv\n",
            "[2025-05-20 06:29:25] üîî New jobs matching user interests:\n",
            "                                        title         company  \\\n",
            "4   Applied AI ML Director - Machine Learning  JPMorgan Chase   \n",
            "5                     Senior Product Designer      Observe.AI   \n",
            "7                              Data Scientist         Spotify   \n",
            "14  Applied AI ML Director - Machine Learning  JPMorgan Chase   \n",
            "15                    Senior Product Designer      Observe.AI   \n",
            "17                             Data Scientist         Spotify   \n",
            "\n",
            "                       location url  \n",
            "4   Hyderabad, Telangana, India      \n",
            "5   Bangalore, Karnataka, India      \n",
            "7    Mumbai, Maharashtra, India      \n",
            "14  Hyderabad, Telangana, India      \n",
            "15  Bangalore, Karnataka, India      \n",
            "17   Mumbai, Maharashtra, India      \n",
            "[2025-05-20 06:29:25] ‚úÖ Job monitoring completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import joblib\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# ----------------------------------\n",
        "# Scrape Jobs from Karkidi\n",
        "# ----------------------------------\n",
        "def scrape_karkidi_jobs(keyword=\"data science\", pages=1):\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    base_url = \"https://www.karkidi.com/Find-Jobs/{page}/all/India?search={query}\"\n",
        "    jobs_list = []\n",
        "\n",
        "    for page in range(1, pages + 1):\n",
        "        url = base_url.format(page=page, query=keyword.replace(' ', '%20'))\n",
        "        print(f\"Scraping page: {page}\")\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        job_blocks = soup.find_all(\"div\", class_=\"ads-details\")\n",
        "        for job in job_blocks:\n",
        "            try:\n",
        "                title = job.find(\"h4\").get_text(strip=True)\n",
        "                company = job.find(\"a\", href=lambda x: x and \"Employer-Profile\" in x).get_text(strip=True)\n",
        "                location = job.find(\"p\").get_text(strip=True)\n",
        "                experience = job.find(\"p\", class_=\"emp-exp\").get_text(strip=True)\n",
        "                key_skills_tag = job.find(\"span\", string=\"Key Skills\")\n",
        "                skills = key_skills_tag.find_next(\"p\").get_text(strip=True) if key_skills_tag else \"\"\n",
        "                summary_tag = job.find(\"span\", string=\"Summary\")\n",
        "                summary = summary_tag.find_next(\"p\").get_text(strip=True) if summary_tag else \"\"\n",
        "\n",
        "                jobs_list.append({\n",
        "                    \"Title\": title,\n",
        "                    \"Company\": company,\n",
        "                    \"Location\": location,\n",
        "                    \"Experience\": experience,\n",
        "                    \"Summary\": summary,\n",
        "                    \"Skills\": skills\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing job block: {e}\")\n",
        "                continue\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    return pd.DataFrame(jobs_list)\n",
        "\n",
        "# ----------------------------------\n",
        "# Preprocess and Clean Skills\n",
        "# ----------------------------------\n",
        "def preprocess_skills(df):\n",
        "    df['Skills_Clean'] = df['Skills'].apply(lambda x: re.sub(r'[^a-zA-Z,]', '', x.lower()))\n",
        "    return df\n",
        "\n",
        "# ----------------------------------\n",
        "# Cluster Jobs by Skills\n",
        "# ----------------------------------\n",
        "def cluster_jobs(df, n_clusters=5):\n",
        "    vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(','), token_pattern=None)\n",
        "    tfidf_matrix = vectorizer.fit_transform(df['Skills_Clean'])\n",
        "\n",
        "    model = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    df['Cluster'] = model.fit_predict(tfidf_matrix)\n",
        "\n",
        "    # Save vectorizer and model\n",
        "    joblib.dump(vectorizer, 'models/tfidf_vectorizer.pkl')\n",
        "    joblib.dump(model, 'models/kmeans_model.pkl')\n",
        "\n",
        "    score = silhouette_score(tfidf_matrix, df['Cluster'])\n",
        "    print(f\"Silhouette Score: {score:.3f}\")\n",
        "    return df\n",
        "\n",
        "# ----------------------------------\n",
        "# Notify Users by Email (Optional)\n",
        "# ----------------------------------\n",
        "def notify_users(df, user_clusters, user_email):\n",
        "    matched = df[df['Cluster'].isin(user_clusters)]\n",
        "    if matched.empty:\n",
        "        print(\"No matching jobs for user.\")\n",
        "        return\n",
        "\n",
        "    msg_body = \"New jobs matching your interests:\\n\\n\"\n",
        "    for _, job in matched.iterrows():\n",
        "        msg_body += f\"{job['Title']} at {job['Company']} - {job['Location']}\\n\"\n",
        "\n",
        "    msg = MIMEText(msg_body)\n",
        "    msg['Subject'] = 'Job Alert: New Matching Jobs'\n",
        "    msg['From'] = 'your_email@gmail.com'  # Replace with your email\n",
        "    msg['To'] = user_email\n",
        "\n",
        "    try:\n",
        "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
        "            server.starttls()\n",
        "            server.login('your_email@gmail.com', 'your_app_password')  # Replace with your email and app password\n",
        "            server.send_message(msg)\n",
        "        print(f\"Notification sent to {user_email}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Email failed: {e}\")\n",
        "\n",
        "# ----------------------------------\n",
        "# Main Execution\n",
        "# ----------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    df = scrape_karkidi_jobs(keyword=\"data science\", pages=2)\n",
        "    if df.empty:\n",
        "        print(\"No jobs scraped. Please check page structure or keyword.\")\n",
        "    else:\n",
        "        df = preprocess_skills(df)\n",
        "        df = cluster_jobs(df)\n",
        "        df.to_csv('data/karkidi_jobs_clustered.csv', index=False)\n",
        "        print(\"Jobs saved to data/karkidi_jobs_clustered.csv\")\n",
        "\n",
        "        # Optional: Notify user of relevant clusters\n",
        "        user_clusters = [0, 2]  # Example cluster preferences\n",
        "        notify_users(df, user_clusters, 'recipient_email@example.com')  # Replace with recipient's email\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "afxoCo9B_Qer",
        "outputId": "3526dc29-5bc2-4e39-a8be-7c28250644e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page: 1\n",
            "Scraping page: 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PicklingError",
          "evalue": "Can't pickle <function cluster_jobs.<locals>.<lambda> at 0x78ca62dd5440>: it's not found as __main__.cluster_jobs.<locals>.<lambda>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-175fcced7ae1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_skills\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/karkidi_jobs_clustered.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jobs saved to data/karkidi_jobs_clustered.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-175fcced7ae1>\u001b[0m in \u001b[0;36mcluster_jobs\u001b[0;34m(df, n_clusters)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Save vectorizer and model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/tfidf_vectorizer.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/kmeans_model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate_setter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mobj2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             raise PicklingError(\n\u001b[0m\u001b[1;32m   1072\u001b[0m                 \u001b[0;34m\"Can't pickle %r: it's not found as %s.%s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                 (obj, module_name, name)) from None\n",
            "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function cluster_jobs.<locals>.<lambda> at 0x78ca62dd5440>: it's not found as __main__.cluster_jobs.<locals>.<lambda>"
          ]
        }
      ]
    }
  ]
}